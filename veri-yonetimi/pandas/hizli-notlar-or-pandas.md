# ğŸƒâ€â™‚ï¸ HÄ±zlÄ± Notlar \| Pandas

## ğŸ”— FaydalÄ± BaÄŸlantÄ±lar

* [Neden SQL deÄŸil de bu?](https://datascience.stackexchange.com/a/34366)
* [DÃ¶kÃ¼mantasyon](https://pandas.pydata.org/pandas-docs/stable/user_guide/)
* [SQL to Pandas](https://medium.com/jbennetcodes/how-to-rewrite-your-sql-queries-in-pandas-and-more-149d341fc53e)

## HÄ±zlÄ± Notlar

* `df.dtypes` Tablodaki Ã¶zellikleri listeler

Json okuma \`\`\`py import gzip import simplejson as json with gzip.open\('./data/yelp.json.gz', 'r'\) as f: yelp\_data = \[json.loads\(line\) for line in f\] yelp\_df = pd.DataFrame\(yelp\_data\) yelp\_df.head\(\) \`\`\`

## DataFrame Series

* Datafrme `dict of Series` ÅŸeklinde tanÄ±mlanÄ±r
* Seriler aynÄ± `np.array` gibidir
  * `index` ile boyutlarÄ±nÄ± gÃ¶rebiliriz
  * `RangeIndex(start=0, stop=37938, step=1)`
* `yelp_df[100]['city']` ÅŸeklinde eriÅŸim olmaz
  * `yelp_df['city'][100]` ÅŸeklinde 100. Ã¶ÄŸeye eriÅŸilir
  * Veya `yelp_df.loc[100, 'city']` ÅŸeklinde 100.verinin ÅŸehir verisi alÄ±nÄ±r

## HÄ±zlÄ± Kod NotlarÄ±

```python
df = pd.DataFrame({'shoe_size': shoes, 'jersey_size': jerseys}, index = players)
df = pd.DataFrame(list(zip(shoes, jerseys)), columns = ['shoe_size', 'jersey_size'], index = players)
print(df['shoe_size'])
print(np.log(df))
df.mean()
print(df.loc['Ronaldo'])
print(df.loc[['Ronaldo', 'George Best'], 'shoe_size'])
# can also select position-based slices of data
print(df.loc['Ronaldo':'George Best', 'shoe_size'])
# for position-based indexing, we will typically use iloc
print(df.iloc[:5])
print(df.iloc[2:4, 0])
# to see just the top of the DataFrame, use head
df.head()
# of for the bottom use tail
df.tail()
# adding a new column
df['position'] = np.random.choice(['goaltender', 'defense', 'midfield', 'attack'], size=len(df))
df.head()
# adding a new row
df.loc['Dylan'] = {'jersey_size': 91, 'shoe_size': 9, 'position': 'midfield'}
df.loc['Dylan']
df.drop('Dylan')
df.drop('position', axis=1)
df = df.drop('Dylan')
print(df)
df.drop('position', axis=1, inplace=True)
print(df)
```

## Veri Ã‡ekme

* Gzip'ten alabiliyor

```python
col_names=[ 'code', 'name', 'addr_1', 'addr_2', 'borough', 'village', 'post_code']
practices = pd.read_csv("dw-data/practices.csv.gz", names=col_names)
pratices.head() # BaÅŸÄ± gÃ¶sterme
pratices.tail() # Sonu gÃ¶sterme

scripts['items'].sum() # TÃ¼m items deÄŸerlerini toplama
pratices.describe() # veri sayÄ±sÄ±, ortalama, standart sapma, min, 1.Ã§eyrek, medyan, 2.Ã§eyerk, max

# count  973193.000000  973193.000000  973193.000000  973193.000000
# mean        9.133136      73.058915      67.986613     741.329835
# std        29.204198     188.070257     174.401703    3665.426958
# min         1.000000       0.000000       0.040000       0.000000
# 25%         1.000000       7.800000       7.330000      28.000000
# 50%         2.000000      22.640000      21.220000     100.000000
# 75%         6.000000      65.000000      60.670000     350.000000
# max      2384.000000   16320.000000   15108.320000  577720.000000

scripts.groupby("bnf_name").sum() # TÃ¼m deÄŸerleri toplama ve bnf_name'e gÃ¶re gruplama
sum_bnf_items = sums_bnf['items']
most_common_item = [(sum_bnf_items.idxmax(), sum_bnf_items.max())]
# idmax: ID max: DeÄŸeri dÃ¶ndÃ¼rÃ¼r
df.loc[sum_bnf_items.idxmax()] # Max eleman satÄ±rÄ±nÄ± basma

df.filter(['a', 'b']) # sadece a b sÃ¼tÃ¼nunu gÃ¶sterme
```

## BirleÅŸtirme

```python
# Indexlere gÃ¶re otomatik birleÅŸtirme
pd.concat([scripts, practices], axis=1, join='inner')

concated_data['sums'] = concated_data.groupby(["post_code"])['items'].transform('sum') # AynÄ± post koda gÃ¶re toplama
```

## Drop Ä°ÅŸlemleri

* [Pandas Drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)

## Harici Linkler

* [Group by one columns and find sum and max value for another in pandas](https://stackoverflow.com/a/44725963/9770490)

