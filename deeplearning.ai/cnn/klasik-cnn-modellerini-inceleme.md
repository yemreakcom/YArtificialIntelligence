# ğŸ‘â€ğŸ—¨ Klasik CNN Modellerini Ä°nceleme

## Klasik Sinir AÄŸlarÄ±

| Network | AÃ§Ä±klama |
| :--- | :--- |
| LeNet - 5 | SayÄ±larÄ± algÄ±lamak iÃ§in kullanÄ±lan eski bir sistem |
| AlexNet | LeNet'e Ã§ok benzerdir ama Ã§ok daha bÃ¼yÃ¼ktÃ¼r \(Ã§ok hyperparam\) |
| VGG - 16 | OldukÃ§a sade bir sinir aÄŸÄ± sistemi vardÄ±r |

## LeNet - 5

* ArtÄ±k kullanÄ±lmayan:
  * Pek iÅŸe yaramayan `softmax` algoritmasÄ±nÄ± kullanÄ±r
  * `avg pooling` \(artÄ±k `max pooling` iÅŸlemi yapÄ±lÄ±yor\)
* 6'dan 16'a geÃ§iÅŸ aÅŸamasÄ±nda boyut deÄŸiÅŸmekte, gÃ¼nÃ¼mÃ¼zde _pooling_ iÅŸlemlerinde _channel_ **deÄŸiÅŸtirilmez**.
  * _Channel_ deÄŸiÅŸtirmek karmaÅŸÄ±klÄ±ÄŸÄ± arttÄ±racaktÄ±r
  * _Pooling_ iÅŸlemlerinde `sigmoid` / `tanh` kullandÄ±ÄŸÄ±ndan lineerliÄŸi bozar. \(`ReLU` kullanÄ±lmalÄ±ydÄ±\)
  * _graph transfer network_ yapÄ±sÄ± gÃ¼nÃ¼mÃ¼zde yaygÄ±n olarak kullanÄ±lmamakta
* Makalesi okumasÄ± zor tÃ¼rdendir.
* 60k parametresi vardÄ±r

LeNet - 5 Mimarisi !\[\]\(../../res/ex\_lenet5.png\)

## AlexNet

* LeNet'e Ã§ok benzemektedir ama Ã§ok daha bÃ¼yÃ¼ktÃ¼r
* 60M parametresi vardÄ±r \(Ã§ok fazla\)
  * Dikkate deÄŸer alan Ã¼zerinde eÄŸitim yapÄ±lmaktadÄ±r
* Ã‡ok daha fazla gizli birime ve Ã§ok daha fazla veri Ã¼zerinde eÄŸitim alabildikleri gerÃ§eÄŸine dayanarak gÃ¶rÃ¼ntÃ¼ Ã¼zerinde sadece dikkate deÄŸer bir performansa sahip olmasÄ±na izin veren veri setini eÄŸitmiÅŸlerdir.

> Orjinalinde \(224,224\) iken \(227, 227\) olarak kullanÄ±lmasÄ± daha etkili imiÅŸ. ~ Andrew Ng

AlexNet mimarisi !\[\]\(../../res/ex\_alexnet.png\)

## VGG - 16

* Ã‡ok fazla hyperparam yerine daha sade bir yapÄ± kullanÄ±lÄ±r
* Sinir aÄŸlarÄ± mimarisini **sadeleÅŸtirir**
* 16 ifadesi parametreli 16 katmanÄ± olduÄŸu anlamÄ±na gelir
* 138M parametresi vardÄ±r
  * Normala gÃ¶re oldukÃ§a fazladÄ±r
* VGG - 19 kadar iyi olduÄŸundan Ã§ok fazla kullanÄ±lÄ±r

> V66'de her convolutinal iÅŸlemi 2'nin katlarÄ± olarak ilerler. \(Sistematiktir\)

VGG - 16 Mimarisi !\[\]\(../../res/vgg\_ex\_16.png\)

