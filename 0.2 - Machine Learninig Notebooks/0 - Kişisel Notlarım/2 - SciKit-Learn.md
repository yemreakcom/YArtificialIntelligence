# ğŸ“‰ SciKit-Learn

## ğŸ¤– Model MetodlarÄ±

| Metod         | AÃ§Ä±klama                                                 |
| ------------- | -------------------------------------------------------- |
| `fit(x, y)`   | Modeli veriyle eÄŸitmek                                   |
| `predict(X)`  | Modelin tahmin etmesi                                    |
| `score(X, y)` | Tahmin skorunu (ihtimalini) verir                        |
| `coef_`       | AÄŸÄ±rlÄ±k katsayÄ±larÄ±nÄ±n ($$ÃŸ_{1...n}$$) deÄŸerlerini verir |
| `intercept_`  | Sabit sayÄ± (bias $$ÃŸ_0$$) deÄŸerini verir                 |

### ğŸ³ AÄŸÄ±rlÄ±k ve Bias DeÄŸerlerine Ã–rnek

$$ y(X) = \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5 x_5 + \beta_6 x_6 + \beta_7 x_7 + \beta_8 x_8 + \beta_0. $$


```py
print("Î²_0: {}".format(model.intercept_))
for i in range(8):
    print("Î²_{}: {}".format(i+1, model.coef_[i]))
```

```py
Î²_0: -36.94192020718441
Î²_1: 0.4366932931343245
Î²_2: 0.009435778033237972
Î²_3: -0.10732204139090447
Î²_4: 0.645065693519812
Î²_5: -3.976389421211576e-06
Î²_6: -0.003786542654971
Î²_7: -0.42131437752714385
Î²_8: -0.43451375467477743
```

## ğŸ’« Transformers (DÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ler)

Makine Ã¶ÄŸrenimi iÃ§in her zaman veriler istenildiÄŸi dÃ¼zende olmaz, bu durumlarda **Transformers**'lar kullanÄ±lÄ±r

- Temel amacÄ± verileri benzer hale  getirmektir
  - Verilerin benzer olmasÄ± makine Ã¶ÄŸrenimi her zaman **hÄ±zlandÄ±rÄ±r**
- Verileri aynÄ± Ã¶lÃ§ekte alttaki koÅŸullara gÃ¶re dÃ¼zenler (**normalizasyon** denebilir (?))
  - Aritmatik OrtalamasÄ± = 0
  - VaryansÄ± = 1
    - Varyans, bir serinin aritmatik ortalamasÄ± Ã¼zerinde daÄŸÄ±lÄ±mÄ±dÄ±r
    - [Varyans hesaplama](https://www.wikihow.com.tr/Varyans-Nas%C4%B1l-Hesaplan%C4%B1r)

```py
from sklearn.preprocessing import StandardScaler

# create and fit scaler
scaler = StandardScaler()
scaler.fit(X)

# scale data set
Xt = scaler.transform(X)

# create data frame with results
stats = np.vstack((X.mean(axis=0), X.var(axis=0), Xt.mean(axis=0), Xt.var(axis=0))).T
feature_names = data['feature_names']
columns = ['DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmemiÅŸ Ortalama', 'DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmemiÅŸ Varyans', 'DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ Ortalama', 'DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ Varyans']

df = pd.DataFrame(stats, index=feature_names, columns=columns)
df
```

![](../../res/scikit_learn_variance.png)

### ğŸ§± Transformers MetodlarÄ±

| Metod              | AÃ§Ä±klama                                 |
| ------------------ | ---------------------------------------- |
| `fit(x, y)`        | Modeli veriyle eÄŸitmek                   |
| `transform(X)`     | Veriyi dÃ¶nÃ¼ÅŸtÃ¼rmek ve verimli hale almak |
| `fit_transform(X)` | Ã–nce `fit` ardÄ±ndan `transform` uygular  |

### ğŸ“Š ColumnTransformers

Sadece **belirlenen** sÃ¼tÃ¼nlara dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemi uygulamak iÃ§in tercih edilir

```py
from sklearn.compose import ColumnTransformer

col_transformer = ColumnTransformer(
    remainder='passthrough',
    transformers=[
        ('scaler', StandardScaler(), slice(0,6)) # first 6 columns
    ]
)

col_transformer.fit(X)
Xt = col_transformer.transform(X)

print('MedInc mean before transformation?', X.mean(axis=0)[0]) # 3.8706710029069766
print('MedInc mean after transformation?', Xt.mean(axis=0)[0], '\n') # 6.609699867535816e-17

print('Longitude mean before transformation?', X.mean(axis=0)[-1]) # -119.56970445736432
print('Longitude mean after transformation?', Xt.mean(axis=0)[-1]) # -119.56970445736432

col_transformer = ColumnTransformer(
    remainder='passthrough',
    transformers=[
        ('remove', 'drop', 0),
        ('scaler', StandardScaler(), slice(1,6))
    ]
)

Xt = col_transformer.fit_transform(X)

print('Number of features in X:', X.shape[1]) # 8
print('Number of features Xt:', Xt.shape[1]) # 7
```

## ğŸ¢ Pipeline

Birden fazla iÅŸlemleri **seri** olarak yapmayÄ± saÄŸlayan yÃ¶ntemdir

```py
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures

# construct pipeline
scaler = StandardScaler()
poly_features = PolynomialFeatures(degree=2)
lin_reg = LinearRegression()

pipe = Pipeline([
    ('scaler', scaler),
    ('poly', poly_features),
    ('regressor', lin_reg)
])

print(pipe.named_steps)
# {'scaler': StandardScaler(copy=True, with_mean=True, with_std=True),
# 'poly': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False,
#                  order='C'),
# 'regressor': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)}

pipe.fit(X, y)
y_pred = pipe.predict(X)

print(y_pred) # [4.00298901 3.92349228 3.99012926 ... 0.83369975 0.88801566 0.97559649]
print("R^2: {}".format(pipe.score(X, y))) # R^2: 0.6832976293317492
```

